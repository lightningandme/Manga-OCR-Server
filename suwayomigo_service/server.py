import base64
import os
import sys
import cv2
import numpy as np
import uvicorn
from PIL import Image
from fastapi import FastAPI, Body
from dotenv import load_dotenv

# å…³é”®ï¼šå°†é¡¹ç›®æ ¹ç›®å½•åŠ å…¥ç³»ç»Ÿè·¯å¾„
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

from manga_ocr import MangaOcr
from janome.tokenizer import Tokenizer

from openai import OpenAI
import time

import warnings
# å±è”½æ‰æ¥è‡ª huggingface_hub çš„ FutureWarning
warnings.filterwarnings("ignore", category=FutureWarning, module="huggingface_hub")

# åŠ è½½å½“å‰ç›®å½•ä¸‹çš„ .env æ–‡ä»¶
load_dotenv()

# ä»ç¯å¢ƒå˜é‡ä¸­è¯»å–
api_key = os.getenv("DEEPSEEK_API_KEY")
base_url = os.getenv("DEEPSEEK_BASE_URL")
# --- é…ç½® DeepSeek ---
client = OpenAI(
    api_key=api_key,
    base_url=base_url
)

app = FastAPI()

# åˆå§‹åŒ– OCR æ¨¡å‹
print("Loading Manga-OCR model...")
mocr = MangaOcr()

# åˆå§‹åŒ– Janome åˆ†è¯å™¨ (æœ¬åœ°è¿è¡Œï¼Œæå¿«)
print("Initializing Tokenizer...")
tokenizer = Tokenizer()


def get_smart_crop(image_bytes, click_x_rel, click_y_rel):
    """
        é’ˆå¯¹å‰ç«¯è¾“å…¥ä¼˜åŒ–çš„åˆ‡å›¾ç®—æ³•
        click_x_rel, click_y_rel: ç‚¹å‡»ç‚¹åœ¨å±€éƒ¨å›¾ä¸­çš„ç›¸å¯¹åæ ‡
        """
    nparr = np.frombuffer(image_bytes, np.uint8)
    img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
    if img is None: return None
    h, w = img.shape[:2]  # æ­¤æ—¶ h, w ç†è®ºä¸Šéƒ½æ˜¯ 600

    cx, cy = int(click_x_rel), int(click_y_rel)
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    # --- 1. è‡ªåŠ¨çº åï¼ˆå›ºå®šåŠå¾„ 20pxï¼‰ ---
    search_radius = 20
    blurred = cv2.GaussianBlur(gray, (5, 5), 0)
    min_y, max_y = max(0, cy - search_radius), min(h, cy + search_radius)
    min_x, max_x = max(0, cx - search_radius), min(w, cx + search_radius)
    sub = blurred[min_y:max_y, min_x:max_x]

    if sub.size > 0:
        _, max_val, _, max_loc = cv2.minMaxLoc(sub)
        if max_val > 180:
            cx, cy = min_x + max_loc[0], min_y + max_loc[1]

    # --- 2. é­”æ³•æ£’æ¢æµ‹ ---
    ff_mask = np.zeros((h + 2, w + 2), np.uint8)
    flood_filled = gray.copy()
    # ç¨å¾®æ”¾å®½å®¹å·®å€¼ï¼ˆ18, 18ï¼‰ï¼Œæ›´é€‚åˆ 600px çš„æ–‡å­—å¯†åº¦
    cv2.floodFill(flood_filled, ff_mask, (cx, cy), 255, (18,), (18,), cv2.FLOODFILL_FIXED_RANGE)
    bubble_mask = ff_mask[1:-1, 1:-1] * 255

    cnts, _ = cv2.findContours(bubble_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    is_leaking = False
    if cnts:
        c = max(cnts, key=cv2.contourArea)
        x, y, rw, rh = cv2.boundingRect(c)
        area = cv2.contourArea(c)

        # ã€å…³é”®æ”¹è¿›ã€‘ï¼šå¤šç»´åº¦åˆ¤å®šâ€œè¿™åˆ°åº•æ˜¯ä¸æ˜¯ä¸ªæ°”æ³¡â€
        # 1. é¢ç§¯å¤ªå¤§ (è¶…è¿‡ 60%)
        # 2. å½¢çŠ¶å¤ªæ–¹ (æ°”æ³¡é€šå¸¸æ˜¯åœ†æ¶¦æˆ–æ¤­åœ†çš„ï¼Œå¦‚æœå®½é«˜æ¯”æ¥è¿‘å…¨å›¾ä¸”å¡«æ»¡äº†çŸ©å½¢ï¼Œé€šå¸¸æ˜¯èƒŒæ™¯)
        rect_area = rw * rh
        solidity = area / float(rect_area) if rect_area > 0 else 0

        if rw > w * 0.8 or rh > h * 0.8 or area > (w * h * 0.6):
            is_leaking = True
        # 3. å¦‚æœé€‰ä¸­åŒºåŸŸæ˜¯ä¸€ä¸ªéå¸¸æ–¹æ­£çš„å¤§è‰²å—ï¼ˆsolidityå¾ˆé«˜ä¸”é¢ç§¯ä¸å°ï¼‰ï¼Œé€šå¸¸æ˜¯èƒŒæ™¯æ¼æ°”
        elif solidity > 0.9 and area > (w * h * 0.3):
            is_leaking = True
            print("ğŸ›¡ï¸ æ£€æµ‹åˆ°é«˜å®å¿ƒåº¦å¤§è‰²å—ï¼Œç–‘ä¼¼èƒŒæ™¯æ¼æ°”ï¼Œåˆ‡æ¢èšåˆæ¨¡å¼")
    else:
        is_leaking = True

    # --- 3. é€»è¾‘åˆ†æ”¯ ---
    if not is_leaking:
        # æƒ…å†µ Aï¼šæ°”æ³¡æ•è·ï¼Œä½¿ç”¨å›ºå®š 25px é—­è¿ç®—
        print("--- æ¨¡å¼ï¼šå¯¹è¯æ°”æ³¡æ•è· ---")
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (25, 25))
        bubble_mask = cv2.morphologyEx(bubble_mask, cv2.MORPH_CLOSE, kernel)
        cnts, _ = cv2.findContours(bubble_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        c = max(cnts, key=cv2.contourArea)
        x, y, rw, rh = cv2.boundingRect(c)
        pad = 10
    else:
        # --- æ¨¡å¼ï¼šå®šå‘æµå‘èšåˆ (é’ˆå¯¹å¤šåˆ—æ’ç‰ˆä¼˜åŒ–) ---
        print("--- æ¨¡å¼ï¼šå®šå‘æµå‘èšåˆ ---")

        # 1. å¸¸è§„è¾¹ç¼˜
        edges = cv2.Canny(gray, 60, 180)
        # 2. å¸¸è§„é«˜å…‰ (æŠ“ç™½å­—/ç™½è¾¹)
        _, bright_mask = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY)
        # 3. å±€éƒ¨å¯¹æ¯”åº¦ (ä¸“é—¨å¯¹ä»˜é»‘åº•é»‘å­—+ç™½è¾¹)
        # å®ƒèƒ½è¯†åˆ«å‡ºé»‘èƒŒæ™¯ä¸­ç»†å¾®çš„äº®åº¦å˜åŒ–
        adaptive_mask = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                                              cv2.THRESH_BINARY_INV, 15, 8)

        # èåˆ
        combined_features = cv2.bitwise_or(edges, bright_mask)
        combined_features = cv2.bitwise_or(combined_features, adaptive_mask)

        # è¿™é‡Œçš„è†¨èƒ€ä¿æŒä½ åŸæ¥çš„ (3, 30) å’Œ (30, 3)ï¼Œä¸è¦å˜
        kernel_v = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 30))
        kernel_h = cv2.getStructuringElement(cv2.MORPH_RECT, (30, 3))
        dilated = cv2.dilate(combined_features, kernel_v)
        dilated = cv2.dilate(dilated, kernel_h)

        # ä¿å­˜è°ƒè¯•å›¾
        cv2.imwrite("debug_radar_mask.png", dilated)

        r_cnts, _ = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        # æ”¶é›†æ‰€æœ‰å€™é€‰å—ï¼Œå¹¶è¿‡æ»¤æ‰å¤ªå¤§çš„ï¼ˆæ¯”å¦‚æ¼«ç”»è¾¹æ¡†ï¼‰
        candidates = []
        seed_idx = -1

        for i, rc in enumerate(r_cnts):
            rx, ry, rrw, rrh = cv2.boundingRect(rc)
            # è¿‡æ»¤æ‰å‡ ä¹å æ»¡å…¨å›¾çš„è¾¹æ¡†å™ªéŸ³
            if rrw > w * 0.95 or rrh > h * 0.95:
                continue

            candidates.append((rx, ry, rrw, rrh))

            # æ‰¾åˆ°ç‚¹å‡»ç‚¹æ‰€åœ¨çš„å—
            if rx <= cx <= rx + rrw and ry <= cy <= ry + rrh:
                seed_idx = len(candidates) - 1

        if seed_idx != -1:
            # --- ã€æ ¸å¿ƒæ”¹è¿›ã€‘ï¼šåŠ¨æ€ç”Ÿé•¿ + å¯¹é½ä¼˜å…ˆèšåˆ ---

            # åˆå§‹åŒ–èšåˆé›†åˆ
            merged_indices = {seed_idx}

            # ä¸¤ä¸ªæ ¸å¿ƒé˜ˆå€¼
            # 1. FLOW_GAP: é¡ºç€æ–‡å­—æµå‘ï¼ˆå¦‚ç«–æ’çš„ä¸Šä¸‹ï¼‰å…è®¸çš„æœ€å¤§é—´æ–­è·ç¦»
            FLOW_GAP = 120  # ç¨å¾®ç»™å¤§ç‚¹ï¼Œåº”å¯¹ä¸€äº›è‰ºæœ¯æ’ç‰ˆçš„å¤§ç©ºéš™
            # 2. CROSS_GAP: å‚ç›´äºæµå‘ï¼ˆå¦‚ç«–æ’çš„æ¢åˆ—ï¼‰å…è®¸çš„æœ€å¤§åç¦»è·ç¦»
            CROSS_GAP = 15  # å¿…é¡»å¾ˆå°ï¼Œé˜²æ­¢è¿åˆ°éš”å£åˆ—å»

            has_new_merge = True

            while has_new_merge:
                has_new_merge = False

                # 1. è·å–å½“å‰å¤§å›¢å—çš„å°ºå¯¸å’Œè¾¹ç•Œ
                current_rects = [candidates[i] for i in merged_indices]
                min_x = min([r[0] for r in current_rects])
                min_y = min([r[1] for r in current_rects])
                max_x = max([r[0] + r[2] for r in current_rects])
                max_y = max([r[1] + r[3] for r in current_rects])
                curr_w = max_x - min_x
                curr_h = max_y - min_y

                # 2. åŠ¨æ€åˆ¤æ–­å½“å‰å¤§å›¢å—çš„æµå‘
                # éšç€åˆå¹¶çš„è¿›è¡Œï¼Œis_vertical å¯èƒ½ä¼šä» False å˜æˆ True
                is_vertical = curr_h > curr_w * 1.1
                is_horizontal = curr_w > curr_h * 1.1
                # å¦‚æœéƒ½ä¸æ˜¯ï¼Œè¯´æ˜è¿˜æ˜¯ä¸ªæ–¹å—ï¼ˆambiguousï¼‰ï¼Œæ­¤æ—¶ä¾é å¯¹é½åº¦æ¥åˆ¤æ–­

                # 3. éå†å¯»æ‰¾å¯ä»¥åå™¬çš„é‚»å±…
                for i in range(len(candidates)):
                    if i in merged_indices: continue

                    ox, oy, ow, oh = candidates[i]
                    ox2, oy2 = ox + ow, oy + oh

                    should_merge = False

                    # è®¡ç®—æŠ•å½±é‡å åº¦ï¼ˆåˆ¤æ–­å¯¹é½ï¼‰
                    # Xè½´é‡å é•¿åº¦ / è¾ƒå°çš„é‚£ä¸€ä¸ªå®½åº¦
                    overlap_x = max(0, min(max_x, ox2) - max(min_x, ox))
                    ratio_align_v = overlap_x / min(curr_w, ow) if min(curr_w, ow) > 0 else 0

                    # Yè½´é‡å é•¿åº¦ / è¾ƒå°çš„é‚£ä¸€ä¸ªé«˜åº¦
                    overlap_y = max(0, min(max_y, oy2) - max(min_y, oy))
                    ratio_align_h = overlap_y / min(curr_h, oh) if min(curr_h, oh) > 0 else 0

                    # è®¡ç®—é—´è·
                    dist_x = max(0, max(min_x, ox) - min(max_x, ox2))
                    dist_y = max(0, max(min_y, oy) - min(max_y, oy2))

                    # === åˆ¤å®šé€»è¾‘ A: æ˜ç¡®çš„ç«–æ’æ¨¡å¼ ===
                    if is_vertical:
                        # å¿…é¡»åœ¨Xè½´é«˜åº¦å¯¹é½ (åŒä¸€åˆ—) ä¸” Yè½´è·ç¦»åœ¨å…è®¸èŒƒå›´å†…
                        # æˆ–è€… è·ç¦»æè¿‘çš„æ ‡ç‚¹ç¬¦å·
                        if (ratio_align_v > 0.5 and dist_y < FLOW_GAP) or (dist_x < CROSS_GAP and dist_y < CROSS_GAP):
                            should_merge = True

                    # === åˆ¤å®šé€»è¾‘ B: æ˜ç¡®çš„æ¨ªæ’æ¨¡å¼ ===
                    elif is_horizontal:
                        # å¿…é¡»åœ¨Yè½´é«˜åº¦å¯¹é½ (åŒä¸€è¡Œ) ä¸” Xè½´è·ç¦»åœ¨å…è®¸èŒƒå›´å†…
                        if (ratio_align_h > 0.5 and dist_x < FLOW_GAP) or (dist_x < CROSS_GAP and dist_y < CROSS_GAP):
                            should_merge = True

                    # === åˆ¤å®šé€»è¾‘ C: æ–¹å—/ä¸å®šçŠ¶æ€ (å…³é”®ä¿®å¤ç‚¹) ===
                    else:
                        # æ—¢ä¸æ¨ªä¹Ÿä¸ç«–ï¼Œè¯´æ˜æ˜¯åˆå§‹ç§å­ã€‚
                        # ç­–ç•¥ï¼šè°è·Ÿæˆ‘å¯¹å…¶æœ€å‡†ï¼Œæˆ‘å°±è·Ÿè°è¿ï¼

                        # å¦‚æœè·Ÿä¸‹æ–¹/ä¸Šæ–¹æ–¹å— Xè½´å¯¹é½åº¦æé«˜ -> å°è¯•ç«–å‘åˆå¹¶
                        if ratio_align_v > 0.6 and dist_y < FLOW_GAP:
                            should_merge = True

                        # å¦‚æœè·Ÿå·¦è¾¹/å³è¾¹æ–¹å— Yè½´å¯¹é½åº¦æé«˜ -> å°è¯•æ¨ªå‘åˆå¹¶
                        elif ratio_align_h > 0.6 and dist_x < FLOW_GAP:
                            should_merge = True

                        # ä¿åº•ï¼šå¦‚æœè·ç¦»ç‰¹åˆ«è¿‘ï¼Œä¸ç®¡å¯¹é½ä¸å¯¹é½éƒ½å¸è¿›æ¥ (å¤„ç†æ ‡ç‚¹)
                        elif dist_x < 20 and dist_y < 20:
                            should_merge = True

                    if should_merge:
                        merged_indices.add(i)
                        has_new_merge = True
                        # åªè¦æœ‰ä¸€ä¸ªæ–°å—åŠ è¿›æ¥ï¼Œå°±ä¼šæ”¹å˜å¤§å›¢å—çš„å®½é«˜æ¯”
                        # ä¸‹ä¸€æ¬¡å¾ªç¯å°±ä¼šæ ¹æ®æ–°çš„å½¢çŠ¶é‡æ–°åˆ¤æ–­ is_vertical/is_horizontal
                        # ä»è€Œè§¦å‘â€œè¿é”ååº”â€
                        break  # é‡æ–°è®¡ç®—å¤§åŒ…å›´ç›’ï¼Œè¿›å…¥ä¸‹ä¸€æ¬¡ while å¾ªç¯

            # æœ€ç»ˆè¾“å‡º
            x, y = min_x, min_y
            rw, rh = max_x - min_x, max_y - min_y
            pad = 20
        else:
            # ä¿åº•
            print("--- æ¨¡å¼ï¼šè§¦å‘ä¿åº•è¯†åˆ«èŒƒå›´ ---")
            # --- æ”¹è¿›çš„åŠ¨æ€ä¿åº•é€»è¾‘ ---
            # å®šä¹‰ä¿åº•æ¡†å åŸå›¾çš„æ¯”ä¾‹ï¼ˆä¾‹å¦‚ï¼šå®½å  50%ï¼Œé«˜å  25%ï¼‰
            fallback_w = int(w * 0.6)
            fallback_h = int(h * 0.8)

            # è®¡ç®—èµ·å§‹åæ ‡ï¼Œä½¿ç‚¹å‡»ç‚¹å¤„äºæ¡†çš„ä¸­å¿ƒ
            x = cx - (fallback_w // 2)
            y = cy - (fallback_h // 2)
            rw, rh, pad = fallback_w, fallback_h, 0

    # --- 4. æœ€ç»ˆè£å‰ªå¹¶ç¡®ä¿ä¸è¶Šç•Œ ---
    x1, y1 = max(0, x - pad), max(0, y - pad)
    x2, y2 = min(w, x + rw + pad), min(h, y + rh + pad)

    # --- è°ƒè¯•ä»£ç å¼€å§‹ (æ’å…¥åœ¨ return ä¹‹å‰) ---
    debug_img = img.copy()
    # ç”»å‡ºæœ€ç»ˆç¡®å®šçš„çŸ©å½¢æ¡† (çº¢è‰²ï¼Œç²—ç»†ä¸º 3)
    cv2.rectangle(debug_img, (x1, y1), (x2, y2), (0, 0, 255), 3)
    # ç”»å‡ºç‚¹å‡»çš„åŸå§‹åæ ‡ç‚¹ (è“è‰²å°åœ†ç‚¹)
    cv2.circle(debug_img, (int(click_x_rel), int(click_y_rel)), 5, (255, 0, 0), -1)

    # ä¿å­˜è°ƒè¯•å›¾ç‰‡åˆ°åç«¯æœåŠ¡å™¨ç›®å½•ä¸‹
    cv2.imwrite("debug_result.png", debug_img)

    return img[y1:y2, x1:x2]

def analyze_text(text: str):
    """
    å¯¹æ—¥è¯­æ–‡æœ¬è¿›è¡Œåˆ†è¯ï¼Œå¹¶æå–å­¦ä¹ ç›¸å…³çš„å…ƒæ•°æ®
    """
    results = []
    # è¿è¡Œåˆ†è¯
    tokens = tokenizer.tokenize(text)

    for token in tokens:
        # pos æ ¼å¼é€šå¸¸ä¸º: åè©,ä¸€èˆ¬,*,*
        pos_details = token.part_of_speech.split(',')
        main_pos = pos_details[0]  # ä¸»è¯æ€§

        # è¿‡æ»¤æ‰æ ‡ç‚¹ç¬¦å·å’Œç©ºç™½ï¼Œåªä¿ç•™æœ‰æ„ä¹‰çš„è¯æ±‡
        if main_pos in ['è¨˜å·', 'åŠ©è©', 'åŠ©å‹•è©'] and token.surface in [' ', 'ã€€', 'ã€‚', 'ã€','ï¼','ï¼','ï¼Ÿ','ï¼š']:
            continue

        results.append({
            "s": token.surface,  # è¡¨é¢å½¢ï¼šæ¼«ç”»é‡Œæ˜¾ç¤ºçš„åŸæ–‡
            "b": token.base_form,  # åŸå‹ï¼šæŸ¥è¯å…¸ç”¨çš„åŸå§‹å½¢æ€
            "p": main_pos,  # è¯æ€§ï¼šåè¯ã€åŠ¨è¯ã€å½¢å®¹è¯ç­‰
            "r": token.reading  # è¯»éŸ³ï¼šç‰‡å‡åè¯»éŸ³ (å¯é€‰)
        })
    return results


def get_ai_translation(text: str, manga_name: str):
    manga, episode = manga_name.rsplit(':', 1) if ':' in manga_name else ("æ—¥æœ¬æ¼«ç”»","æŸä¸€è¯")
    if not text.strip():
        return ""

    try:
        start_time = time.time()
        # ä½¿ç”¨æç®€ Promptï¼šä¸è¦æ±‚è§£é‡Šï¼Œåªè¦æ±‚åœ°é“ç¿»è¯‘å’Œæ ¸å¿ƒè¯åŸå‹
        # noinspection PyTypeChecker

        # æŒ‰ç…§ä½ æä¾›çš„ Prompt æ¨¡æ¿æ„å»º System Content
        system_content = (
            f"ä½ æ˜¯ä¸€ä½ç²¾é€šå¤šé—¨è¯­è¨€çš„æ—¥æœ¬æ¼«ç”»ç¿»è¯‘ä¸“å®¶ï¼Œæ­£åœ¨é˜…è¯»ã€Š{manga}ã€‹çš„{episode}ã€‚ \n"
            "ä½ çš„ä»»åŠ¡æ˜¯å¤„ç†æ¥è‡ª OCR è¯†åˆ«çš„åŸæ–‡ï¼Œå¹¶å®Œæˆä»¥ä¸‹ä¸‰æ­¥ï¼š\n"
            "1. **æ–‡æœ¬æ ¡å¯¹**ï¼šåˆ¤æ–­è¯†åˆ«ç»“æœä¸­æ˜¯å¦å­˜åœ¨å› ç¬”ç”»å¯†é›†å¯¼è‡´çš„é”™åˆ«å­—ï¼Œè¯·ç»“åˆè¯­å¢ƒå°†å…¶ä¿®æ­£ï¼ˆä¾‹å¦‚å°†é”™è¯¯çš„å½¢è¿‘å­—è¿˜åŸä¸ºæ­£ç¡®çš„è¯æ±‡ï¼‰ã€‚\n"
            "2. **é€»è¾‘æ–­å¥**ï¼šåˆ¤æ–­å› æ¼«ç”»æ’ç‰ˆå¯¼è‡´çš„éæ­£å¸¸è¿å­—ï¼Œå¹¶è¿›è¡Œé€»è¾‘æ–­è¡Œæˆ–å¢åŠ æ ‡ç‚¹ï¼Œè¿˜åŸè§’è‰²çœŸå®çš„è¯´è¯èŠ‚å¥ã€‚\n"
            "3. **åœ°é“ç¿»è¯‘**ï¼šåŸºäºä¿®æ­£åçš„åŸæ–‡ï¼Œç»“åˆè¯¥ä½œå“åœ¨æ­¤é˜¶æ®µçš„å‰§æƒ…èƒŒæ™¯å’Œè§’è‰²èº«ä»½è¿›è¡Œç¿»è¯‘ã€‚\n\n"
            "è¯·ç¿»è¯‘æˆåœ°é“ã€æµç•…çš„ä¸­æ–‡ã€‚ç›´æ¥è¿”å›è¯‘æ–‡ã€‚"
        )

        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": system_content},
                {"role": "user", "content": text},
            ],
            stream=False,
            temperature=0.3,  # é™ä½éšæœºæ€§ï¼Œè®©ç¿»è¯‘æ›´ç¨³å®š
            max_tokens=150  # é™åˆ¶è¾“å‡ºé•¿åº¦ï¼Œå‡å°‘ä¼ è¾“è€—æ—¶
        )
        duration = time.time() - start_time
        print(f"AIç¿»è¯‘ å“åº”è€—æ—¶: {duration:.2f}s (æ­£åœ¨çœ‹: ã€Š{manga}ã€‹çš„{episode})")
        return response.choices[0].message.content.strip()
    except Exception as e:
        return f"ç¿»è¯‘å‡ºé”™äº†: {str(e)}"


# ç¼“å­˜æœ€è¿‘ä¸€æ¬¡çš„ OCR æ–‡æœ¬å’Œæ¼«ç”»å
last_ocr_text = ""
last_manga_name = "General"
@app.post("/ocr")
async def perform_ocr(payload: dict = Body(...)):
    global last_ocr_text, last_manga_name  # <--- ä¿®æ”¹è¿™é‡Œï¼ŒåŠ å…¥ last_manga_name
    last_ocr_text = ""  # æ¯æ¬¡è¯†åˆ«æ–°å›¾å‰å…ˆæ¸…ç©ºæ—§ç¼“å­˜
    img_b64 = payload.get("image")
    # è·å– Android ä¼ æ¥çš„ç‚¹å‡»åæ ‡
    click_x = payload.get("x", 0)
    click_y = payload.get("y", 0)
    manga_name = payload.get("mangaName", "General")

    last_manga_name = manga_name  # <--- æ ¸å¿ƒä¿®æ”¹ï¼šå°†æœ¬æ¬¡æ¼«ç”»åå­˜å…¥ç¼“å­˜
    if not img_b64:
        return {"status": "error", "message": "No image data"}

    try:
        # 1. è§£ç ä¸è¯†åˆ«
        img_data = base64.b64decode(img_b64)

        # --- æ™ºèƒ½åˆ‡å›¾æ ¸å¿ƒè°ƒç”¨ ---
        # æ³¨æ„ï¼šè¿™é‡Œçš„ img_data æ˜¯ Android ä¼ æ¥çš„ 400x400 æˆ– 600x600 çš„å±€éƒ¨å›¾
        # è¿™é‡Œçš„ click_x/y åº”è¯¥æ˜¯ç›¸å¯¹äºè¿™å¼ å±€éƒ¨å›¾çš„åæ ‡
        start_time = time.time()
        smart_img_mat = get_smart_crop(img_data, click_x, click_y)

        # å°† OpenCV çš„ Mat è½¬å› PIL Image ç»™ Manga-OCR ä½¿ç”¨
        smart_img_rgb = cv2.cvtColor(smart_img_mat, cv2.COLOR_BGR2RGB)
        image = Image.fromarray(smart_img_rgb)
        duration = time.time() - start_time
        print(f"å›¾ç‰‡æˆªå– å“åº”è€—æ—¶: {duration:.2f}s")

        # åç»­ OCR é€»è¾‘ä¸å˜
        start_time = time.time()
        text = mocr(image)
        last_ocr_text = text  # å­˜å…¥ç¼“å­˜

        words = analyze_text(text)
        duration = time.time() - start_time
        print(f"æ–‡æœ¬å¤„ç† å“åº”è€—æ—¶: {duration:.2f}s")

        # æ ¸å¿ƒï¼šè¿™é‡Œä¸å†è°ƒç”¨ AI ç¿»è¯‘ï¼Œç›´æ¥è¿”å›ï¼Œé€Ÿåº¦æå‡ 200%
        return {
            "status": "success",
            "text": text,
            "words": words,
            "translation": ""  # åˆå§‹ä¸ºç©º
        }
    except Exception as e:
        return {"status": "error", "message": str(e)}


@app.get("/get_translation")
async def get_translation():
    global last_ocr_text, last_manga_name  # <--- å£°æ˜è¯»å–è¿™ä¸¤ä¸ªå…¨å±€å˜é‡
    if not last_ocr_text:
        return {"translation": "æœªæ£€æµ‹åˆ°å¾…ç¿»è¯‘æ–‡å­—"}

    # è°ƒç”¨æ—¶ä¼ å…¥ç¼“å­˜çš„æ¼«ç”»å
    translation = get_ai_translation(last_ocr_text, last_manga_name)
    return {"translation": translation}


if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=12233)